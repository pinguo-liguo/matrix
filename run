#!/bin/bash

# Licensed to the Apache Software Foundation (ASF) under one
# or more contributor license agreements.  See the NOTICE file
# distributed with this work for additional information
# regarding copyright ownership.  The ASF licenses this file
# to you under the Apache License, Version 2.0 (the
# "License"); you may not use this file except in compliance
# with the License.  You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

SCALA_VERSION=2.10
MATRIX_VERSION=0.1.0

FWDIR="$(cd `dirname $0`; pwd)"

# add environment
if [ -f "$FWDIR/conf/matrix-env.sh" ]; then
  . $FWDIR/conf/matrix-env.sh
fi

if [ -f "$FWDIR/conf/spark-env.sh" ]; then
  . $FWDIR/conf/spark-env.sh
fi


if [ "$LAUNCH_WITH_SCALA" == "1" ]; then
  if [ `command -v scala` ]; then
    RUNNER="scala"
  else
    if [ -z "$SCALA_HOME" ]; then
      echo "SCALA_HOME is not set" >&2
      exit 1
    fi
    RUNNER="${SCALA_HOME}/bin/scala"
  fi
else
  if [ `command -v java` ]; then
    RUNNER="java"
  else
    if [ -z "$JAVA_HOME" ]; then
      echo "JAVA_HOME is not set" >&2
      exit 1
    fi
    RUNNER="${JAVA_HOME}/bin/java"
  fi
  if [ -z "$SCALA_LIBRARY_PATH" ]; then
    if [ -z "$SCALA_HOME" ]; then
      echo "SCALA_HOME is not set" >&2
      exit 1
    fi
    SCALA_LIBRARY_PATH="$SCALA_HOME/lib"
  fi
fi

# Build up classpath
CLASSPATH+=":$FWDIR/conf"
CLASSPATH+=":$FWDIR/target/spark-matrix-$MATRIX_VERSION-dependency.jar"

if [ -e "$FWDIR/lib_managed" ]; then
  for jar in `find $FWDIR/lib_managed -name "*.jar"`
  do
    CLASSPATH+=":$jar"
  done
fi

if [ -e "$FWDIR/lib" ]; then
  for jar in `find $FWDIR/lib -name "*.jar"`
  do
    CLASSPATH+=":$jar"
  done
fi

if [ "x$HADOOP_HOME" == "x" ] ; then
  echo "No HADOOP_HOME specified. Shark will run in local-mode"
else
  CLASSPATH+=":$HADOOP_HOME/conf"
fi

SPARK_CLASSPATH=$CLASSPATH

export SPARK_CLASSPATH

JAVA_OPTS="-server -XX:PermSize=64M -XX:MaxPermSize=128m -Xss10m "
JAVA_OPTS+="$SPARK_JAVA_OPTS"
JAVA_OPTS+=" -Xms$SPARK_MASTER_MEM -Xmx$SPARK_MASTER_MEM "

# Figure out whether to run our class with java or with the scala launcher.
# In most cases, we'd prefer to execute our process with java because scala
# creates a shell script as the parent of its Java process, which makes it
# hard to kill the child with stuff like Process.destroy(). However, for
# the Spark shell, the wrapper is necessary to properly reset the terminal
# when we exit, so we allow it to set a variable to launch with scala.
if [ "$SPARK_LAUNCH_WITH_SCALA" == "1" ]; then
  EXTRA_ARGS=""     # Java options will be passed to scala as JAVA_OPTS
else
  CLASSPATH+=":$SCALA_LIBRARY_PATH/scala-library.jar"
  CLASSPATH+=":$SCALA_LIBRARY_PATH/scala-compiler.jar"
  CLASSPATH+=":$SCALA_LIBRARY_PATH/jline.jar"
  # The JVM doesn't read JAVA_OPTS by default so we need to pass it in
  EXTRA_ARGS="$JAVA_OPTS"
fi

echo exec "$RUNNER" -cp "$CLASSPATH" $EXTRA_ARGS "$@"
exec "$RUNNER" -cp "$CLASSPATH" $EXTRA_ARGS "$@"
